# -*- coding: utf-8 -*-
"""ML_Pr2 (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ud3hAyKWJFZ77ieVSKsV129Ypss7RtQm
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Scikit-learn imports (used later)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score

df  = pd.read_csv("/content/uber.csv")

display(df.head())

df.info()

print("\nColumns:", list(df.columns))

print("\nMissing values per column:\n", df.isnull().sum())

# Drop obvious irrelevant columns if they exist (errors='ignore' to avoid exceptions)
df = df.drop(columns=['Unnamed: 0', 'key'], errors='ignore')

# Some basic sanity filters: remove rows with missing pickup_datetime or fare_amount
df = df[~df['pickup_datetime'].isnull()] if 'pickup_datetime' in df.columns else df
df = df[~df['fare_amount'].isnull()] if 'fare_amount' in df.columns else df

print("After dropping irrelevant/missing rows shape:", df.shape)

display(df.head())

if 'pickup_datetime' in df.columns:
    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')
    # Remove any rows where parse failed
    df = df[~df['pickup_datetime'].isnull()]
    df = df.reset_index(drop=True)
    # create time features
    df['hour'] = df['pickup_datetime'].dt.hour
    df['day'] = df['pickup_datetime'].dt.day
    df['month'] = df['pickup_datetime'].dt.month
    df['year'] = df['pickup_datetime'].dt.year
    df['dayofweek'] = df['pickup_datetime'].dt.dayofweek
else:
    print("Warning: pickup_datetime not found â€” time-based features will be unavailable.")

display(df[['pickup_datetime','hour','day','month','year','dayofweek']].head())

numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
print("Numeric cols:", numeric_cols)

for c in numeric_cols:
    missing = df[c].isnull().sum()
    if missing > 0:
        med = df[c].median()
        df[c].fillna(med, inplace=True)
        print(f"Filled {missing} missing in {c} with median={med}")

if 'passenger_count' in df.columns:
    df['passenger_count'] = df['passenger_count'].fillna(1).astype(int)
    df['passenger_count'] = df['passenger_count'].clip(lower=1, upper=6)

if 'fare_amount' in df.columns:
    df = df[df['fare_amount'] > 0]

df = df.reset_index(drop=True)
print("After imputation shape:", df.shape)

def iqr_clip(series, lower_q=0.25, upper_q=0.75):
    Q1 = series.quantile(lower_q)
    Q3 = series.quantile(upper_q)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return series.clip(lower, upper)

cols_to_treat = []
for c in ['fare_amount','passenger_count','hour','dist_travel_km','pickup_longitude','pickup_latitude',
          'dropoff_longitude','dropoff_latitude']:
    if c in df.columns:
        cols_to_treat.append(c)

print("Columns to IQR-clip:", cols_to_treat)
for c in cols_to_treat:
    df[c] = iqr_clip(df[c])

# Optional: show boxplots after clipping for quick visual check (may be many plots)
df[cols_to_treat].plot(kind='box', subplots=True, layout=(int(np.ceil(len(cols_to_treat)/2)),2), figsize=(12,8))
plt.tight_layout()
plt.show()

import sys
try:
    import haversine as hs
except Exception:
    !pip install -q haversine
    import haversine as hs

def haversine_km(row):
    try:
        loc1 = (float(row['pickup_latitude']), float(row['pickup_longitude']))
        loc2 = (float(row['dropoff_latitude']), float(row['dropoff_longitude']))
        return hs.haversine(loc1, loc2)  # returns kilometers by default
    except Exception:
        return np.nan

required_geo = {'pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude'}
if required_geo.issubset(df.columns):
    df['dist_travel_km'] = df.apply(haversine_km, axis=1)
    # drop rows where distance is NaN (bad coords)
    df = df[~df['dist_travel_km'].isnull()].reset_index(drop=True)
else:
    raise KeyError("Geo coordinate columns missing; cannot compute dist_travel_km.")

df = df[(df['dist_travel_km'] >= 0.1) & (df['dist_travel_km'] <= 200)].reset_index(drop=True)
print("After distance filtering, shape:", df.shape)
display(df[['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude','dist_travel_km']].head())

df = df[
    (df['pickup_latitude'].between(-90,90)) &
    (df['dropoff_latitude'].between(-90,90)) &
    (df['pickup_longitude'].between(-180,180)) &
    (df['dropoff_longitude'].between(-180,180))
].reset_index(drop=True)
print("After coordinate sanity check:", df.shape)

num = df.select_dtypes(include=[np.number])
plt.figure(figsize=(12,9))
sns.heatmap(num.corr(), annot=True, fmt=".2f", cmap='coolwarm', square=True)
plt.title("Correlation matrix (numeric features)")
plt.show()

if 'fare_amount' in num.columns:
    corrs = num.corr()['fare_amount'].abs().sort_values(ascending=False)
    print("Top correlations with fare_amount:\n", corrs.head(10))

feature_cols = []
candidates = ['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude',
              'passenger_count','hour','day','month','year','dayofweek','dist_travel_km']
for c in candidates:
    if c in df.columns:
        feature_cols.append(c)

if 'fare_amount' not in df.columns:
    raise KeyError("Expected target column 'fare_amount' not found in dataset.")

X = df[feature_cols].copy()
y = df['fare_amount'].copy()

print("Using features:", feature_cols)
print("X shape:", X.shape, "y shape:", y.shape)
display(X.head())

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)
print("Train/test shapes:", X_train.shape, X_test.shape)

scaler = StandardScaler()
X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)
X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)
display(X_train_scaled.head())

models = {
    'LinearRegression': LinearRegression(),
    'Ridge(alpha=1.0)': Ridge(alpha=1.0, random_state=42),
    'Lasso(alpha=0.1)': Lasso(alpha=0.1, random_state=42, max_iter=5000)
}

results = []

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    results.append({'model': name, 'mse': mse, 'rmse': rmse, 'r2': r2})
    print(f"--- {name} ---")
    print(f"R2: {r2:.4f}, RMSE: {rmse:.4f}, MSE: {mse:.4f}")
    print("First 8 predictions vs actual:\n", np.vstack((y_pred[:8], y_test.values[:8])).T)
    print()

results_df = pd.DataFrame(results).sort_values('r2', ascending=False).reset_index(drop=True)
display(results_df)

best_model_name = results_df.loc[0,'model']
print("Best model according to R2:", best_model_name)
best_model = models[best_model_name]  # these models have been trained already

y_pred_best = best_model.predict(X_test_scaled)
residuals = y_test - y_pred_best

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.scatter(y_pred_best, residuals, alpha=0.5, edgecolor='k')
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted fare")
plt.ylabel("Residuals")
plt.title(f"Residuals vs Predicted ({best_model_name})")

plt.subplot(1,2,2)
sns.histplot(residuals, kde=True)
plt.title("Residuals distribution")
plt.tight_layout()
plt.show()

