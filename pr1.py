# -*- coding: utf-8 -*-
"""pr1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ab1eWk5wFmGEDn43Q3y198DZ7VSgecop
"""

import pandas as pd
import numpy as np

df=pd.read_csv("C:/Users/Admin/Desktop/ML/Wine (2).csv")
df

df.head()

df.columns

df.isnull().sum()

df.dtypes

import seaborn as sns

sns.countplot(x = 'Wine',data=df)

target= df['Wine']

df = df.drop('Wine',axis=1)

df

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(df,target,test_size =0.20,random_state=12)

X_train.head()

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train

X_train = pd.DataFrame(X_train)
X_test = pd.DataFrame(X_test)

X_train.iloc[81]

from sklearn.linear_model import LogisticRegression
model  = LogisticRegression()
model.fit(X_train,y_train)

from sklearn.metrics import classification_report

y_predict= model.predict(X_test)

y_actual=y_test

y_predict

y_actual

print(classification_report(y_actual,y_predict))

sns.heatmap(X_train.corr(),annot=True)

from sklearn.decomposition import PCA
pca = PCA(n_components=2)

tr_comp = pca.fit_transform(X_train)
ts_comp = pca.fit_transform(X_test)

#tr_comp = pd.DataFrame(tr_comp)
#ts_comp = pd.DataFrame(ts_comp)

tr_comp

from sklearn.linear_model import LogisticRegression
pc_model = LogisticRegression()
pc_model.fit(tr_comp,y_train)

y_predict=pc_model.predict(ts_comp)

y_predict

y_actual=y_test

print(classification_report(y_actual,y_predict))

# Get the principal components directly from pca.components_
principal_components = pca.components_

print("Principal Components:")
print(principal_components)

import matplotlib.pyplot as plt

# Create a scatter plot to visualize the principal components
plt.figure(figsize=(8, 6))
plt.scatter(tr_comp[:, 0], tr_comp[:, 1], c=y_train, cmap='viridis', edgecolor='k')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA: Principal Components')
plt.colorbar()
plt.show()

sns.pairplot(X_train)

from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

# -----------------------
# Rename PCA predictions
# -----------------------
y_predict_pca = y_predict   # from PCA model
y_predict_before = y_predict_before if 'y_predict_before' in globals() else None

# But based on your notebook:
# BEFORE PCA predictions = first y_predict
# AFTER PCA predictions = second y_predict

# Let's fetch them properly:
y_predict_before = model.predict(X_test)          # BEFORE PCA
y_predict_after  = pc_model.predict(ts_comp)      # AFTER PCA

# -----------------------
# 1. Accuracy Comparison
# -----------------------
acc_before = accuracy_score(y_actual, y_predict_before)
acc_after = accuracy_score(y_actual, y_predict_after)

print("Accuracy BEFORE PCA:", acc_before)
print("Accuracy AFTER PCA:", acc_after)

# -----------------------
# 2. Classification Reports
# -----------------------
print("\n------------------- BEFORE PCA -------------------")
print(classification_report(y_actual, y_predict_before))

print("\n------------------- AFTER PCA -------------------")
print(classification_report(y_actual, y_predict_after))

# -----------------------
# 3. Bar Graph Comparison
# -----------------------
plt.figure(figsize=(6,4))
plt.bar(["Before PCA", "After PCA"], [acc_before, acc_after], color=["blue", "green"])
plt.ylabel("Accuracy")
plt.title("Logistic Regression Accuracy Comparison")
plt.ylim(0, 1)
plt.show()

# -----------------------
# 4. Percentage Difference
# -----------------------
change = ((acc_after - acc_before) / acc_before) * 100
print(f"\nPercentage change in accuracy after PCA: {change:.2f}%")

